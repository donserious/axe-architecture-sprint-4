[Какие системы логировать]

Сбор логов необходимо собирать со всех систем, включая логи приложений и логи операционной системы.
в INFO лог должны попадать все верхнеуровневые операции с контекстными сущностями, которые использует приложение.
уровень DEBUG для детального логирования. Это может включать информацию о входных
параметрах функций, внутренние состояния объектов и другие технические детали, которые могут помочь в отладке.

1. Изменение статуса заказа:
   Время изменения
   Идентификатор покупателя
   Номер заказа
   Новый статус заказа
   Старый статус заказа
2. Создание нового заказа:
   Время создания
   Идентификатор покупателя
   Номер заказа
   Список товаров в заказе
   Общая стоимость заказа
3. Обновление информации о заказе:
   Время обновления
   Идентификатор покупателя
   Номер заказа
   Измененные поля (например, адрес доставки, контактная информация)
4. Запрос на расчет стоимости изделия
   Время запроса
   Идентификатор покупателя
   Номер заказа
   Идентификатор 3D-модели
   Время, затраченное на расчет
5. Успешное завершение расчета стоимости
   Время завершения
   Идентификатор покупателя
   Номер заказа
   Рассчитанная стоимость
6. Получение заказа через API
   Время получения
   Идентификатор клиента (партнера)
   Номер заказа
   Статус обработки заказа
7. Успешная отправка уведомления клиенту
   Время отправки
   Идентификатор покупателя
   Номер заказа
   Тип уведомления (например, о статусе заказа)

[Мотивация]

1. Причины для добавления логирования
    1. Мониторинг и диагностика: Логирование позволяет отслеживать поведение системы в реальном времени, что помогает
       быстро выявлять и устранять проблемы. Это особенно важно в условиях роста нагрузки и увеличения числа заказов.
       Анализ производительности: Сбор логов помогает анализировать производительность различных компонентов системы,
       выявлять узкие места и оптимизировать процессы.
    2. Улучшение качества обслуживания: Логи позволяют отслеживать взаимодействие с клиентами, что помогает выявлять
       проблемы и улучшать клиентский опыт.
    3. Соответствие требованиям: В некоторых отраслях логирование является обязательным для соблюдения нормативных
       требований и стандартов безопасности.
    4. Улучшение процессов: Анализ логов может выявить неэффективные процессы и помочь в их оптимизации, что приведет к
       снижению затрат и увеличению прибыли.
2. Технические и бизнес-метрики, на которые может повлиять внедрение логирования:
    1. Время отклика системы:
       Техническая метрика: Логирование поможет отслеживать время отклика различных компонентов системы (например, MES,
       CRM, API). Это позволит выявить узкие места и оптимизировать производительность.
       Бизнес-метрика: Уменьшение времени отклика приведет к более быстрому обслуживанию клиентов и повышению их
       удовлетворенности.
    2. Количество ошибок и предупреждений:
       Техническая метрика: Логи ошибок и предупреждений помогут отслеживать частоту возникновения проблем в системе.
       Это позволит команде быстрее реагировать на сбои и минимизировать их влияние.
       Бизнес-метрика: Снижение количества ошибок приведет к уменьшению числа жалоб от клиентов и повышению их доверия к
       компании.
    3. Время обработки заказов:
       Техническая метрика: Логирование позволит отслеживать время, затрачиваемое на обработку заказов, включая расчет
       стоимости и изменение статусов.
       Бизнес-метрика: Уменьшение времени обработки заказов повысит эффективность работы и позволит компании
       обрабатывать больше заказов, что приведет к увеличению выручки.
    4. Уровень удовлетворенности клиентов:
       Бизнес-метрика: Анализ логов взаимодействия с клиентами поможет выявить проблемные области и улучшить качество
       обслуживания. Это может быть измерено через опросы и отзывы клиентов.
       Техническая метрика: Логирование поможет отслеживать время ответа на запросы клиентов и скорость решения их
       проблем.
    5. Эффективность работы команды:
       Техническая метрика: Логи могут помочь отслеживать производительность сотрудников, например, время, затраченное
       на выполнение задач в MES и CRM.
       Бизнес-метрика: Повышение эффективности работы команды приведет к снижению затрат на операционные процессы и
       увеличению прибыли.

[При ограниченности ресурсов]
Что логировать в первую очередь:

1. Система MES
   Почему:
   MES отвечает за управление производственными процессами и расчет стоимости изделий. Проблемы в этой системе могут
   напрямую влиять на выполнение заказов и сроки их доставки. Так же по словам бизнеса есть потенциал двухкратного
   роста.
   Логирование и трейсинг помогут выявить узкие места в производственном процессе, а так же отслеживать время обработки
   заказов и расчета стоимости.
2. Система CRM
   Почему:
   CRM управляет взаимодействием с клиентами и хранит информацию о заказах. Проблемы в этой системе могут привести к
   недовольству клиентов и потере заказов.
   Логирование поможет отслеживать взаимодействие с клиентами, включая создание и обновление заказов, а также обработку
   запросов.
3. API для интеграции с партнерами
   Почему:
   Открытие API для других продавцов ювелирных изделий увеличивает объем заказов, и проблемы в этой системе могут
   привести к значительным потерям. Логирование и трейсинг API помогут отслеживать запросы от партнеров, выявлять ошибки
   и оптимизировать взаимодействие.
4. Система онлайн-магазина
   Почему:
   Онлайн-магазин является основным каналом продаж для конечных клиентов. Проблемы в этой системе могут привести к
   потере продаж и недовольству клиентов. Логирование поможет отслеживать поведение пользователей, выявлять проблемы с
   оформлением заказов и улучшать
   пользовательский опыт.

[Предлагаемое решение]

[jewerly_c4_model_new.drawio](jewerly_c4_model_new.drawio)

[Политика безопасности в отношении логов]

Обработка чувствительных данных:

1. Идентификация чувствительных данных: Нужно определить, какие данные считаются чувствительными.
2. Анонимизация и маскирование: Все чувствительные данные, которые необходимо логировать, должны быть анонимизированы
   или
   замаскированы. Например, вместо полного имени клиента можно логировать только его идентификатор.
3. Шифрование: Логи, содержащие чувствительные данные, должны быть зашифрованы как при передаче, так и при хранении.
4. Доступ к логам:
5. Ролевой доступ: Доступ к логам должен быть ограничен в зависимости от ролей пользователей. Например, разработчики
   могут
   иметь доступ к логам для отладки, в то время как операторы и менеджеры могут иметь доступ только к логам, связанным с
   их
   работой.
6. Аудит доступа: Все действия с логами должны быть записаны, чтобы можно было отслеживать, кто и когда получил доступ к
   логам. Это поможет в случае расследования инцидентов безопасности.
7. Обучение сотрудников: Все сотрудники, имеющие доступ к логам, должны пройти обучение по безопасности данных и
   политике
   работы с логами.

[Политика хранения логов]

Структура хранения:

1. Отдельные индексы: Для каждой системы (MES, CRM, API, онлайн-магазин) следует создать отдельные индексы для хранения
   логов. Это упростит управление логами и их анализ.
2. Стандартизированный формат: Логи должны храниться в стандартизированном формате (например, JSON), чтобы облегчить их
   анализ и обработку.
3. Срок хранения:
   Определение сроков: Логи должны храниться в течение определенного времени в зависимости от их типа:
   Операционные логи: 6 месяцев.
   Логи ошибок и предупреждений: 1 год.
   Логи доступа: 1 год.
4. Автоматическое удаление: После истечения срока хранения логи должны автоматически удаляться, чтобы избежать
   накопления ненужных данных.
5. Размер логов:
   Ограничение размера: Установить лимиты на размер логов для каждой системы. Например, можно установить лимит в 1 ГБ на
   индекс логов. Если размер превышает лимит, старые записи должны быть удалены в соответствии с политикой хранения.
6. Ротация логов: Настройть ротацию логов, чтобы новые записи автоматически добавлялись, а старые удалялись по мере
   необходимости.

[Превращение в систему анализа логов]

1. Настройка алертинга
   Определение критических событий: Определить, какие события требуют немедленного внимания. Это могут быть ошибки,
   превышение порогов производительности, а также необычные паттерны в логах (например, резкий рост числа заказов).
   Настройка алертов: Будем использовать инструменты мониторинга (например, Prometheus, Grafana, ELK) для настройки
   алертов. Алерты могут быть настроены на основе:
   Числа ошибок за определенный период.
   Времени отклика системы, превышающего допустимые значения.
   Резкого увеличения числа определенных событий (например, создание заказов).
   Каналы уведомлений: Настройте каналы уведомлений для алертов, чтобы соответствующие команды (например, IT,
   безопасность, операционная) могли быстро реагировать на инциденты. Это могут быть электронные письма, SMS,
   уведомления в мессенджерах (Slack, Microsoft Teams).
2. Поиск аномалий
   Анализ паттернов: Внедрить инструменты для анализа паттернов в логах. Это может включать использование машинного
   обучения для выявления аномалий, таких как резкие изменения в количестве заказов или других событиях.
   Настройка порогов: Установить пороги для нормального поведения системы. Например, если в обычное время создается 4
   заказа в секунду, а затем это число резко возрастает до 10 000, это должно вызывать тревогу.
   Мониторинг трафика: Настройть мониторинг сетевого трафика, чтобы выявлять возможные DDoS-атаки. Это может включать
   анализ входящих запросов и их частоты.
3. Инструменты для анализа логов
   Внедрение системы анализа логов: Используем инструменты, такие как ELK Stack (Elasticsearch, Logstash, Kibana) или
   Splunk, для сбора, хранения и анализа логов. Эти инструменты позволяют визуализировать данные и быстро находить
   нужную информацию.
   Создание дашбордов: Настроить дашборды для визуализации ключевых метрик и событий. Это поможет командам быстро
   оценивать состояние системы и выявлять проблемы.
   Регулярные отчеты: Настроить автоматическую генерацию отчетов по ключевым метрикам и событиям. Это поможет командам
   отслеживать изменения и выявлять тренды.
4. Реакция на инциденты
   План реагирования на инциденты: Разработать и внедрить план реагирования на инциденты, который будет включать
   действия в случае выявления аномалий или критических событий. Это может включать:
   Уведомление соответствующих команд.
   Анализ инцидента и его причин.
   Принятие мер по устранению проблемы.
   Обучение команды: Обучите команду реагированию на инциденты и работе с инструментами анализа логов. Это поможет
   повысить эффективность работы и снизить время реакции на проблемы.

[критерии выбора технологий для логирования]

Вот таблица с критериями для выбора технологии для работы с логами, а также плюсы и минусы для нескольких популярных
решений: ELK Stack, OpenSearch и Splunk.

| Критерий                      | ELK Stack                                                                             | OpenSearch                                                              | Splunk                                                                     | Graylog                                                                         |
|-------------------------------|---------------------------------------------------------------------------------------|-------------------------------------------------------------------------|----------------------------------------------------------------------------|---------------------------------------------------------------------------------|
| **Лицензия**                  | Elastic License                                                                       | Apache License, Version 2.0                                             | Проприетарная                                                              | GNU General Public License (GPL)                                                |
| **Производительность**        | Высокая производительность, но может требовать оптимизации для больших объемов данных | Высокая производительность, оптимизирован для работы с большими данными | Очень высокая производительность, но может требовать значительных ресурсов | Хорошая производительность, но может быть ограничена при больших объемах данных |
| **Масштабируемость**          | Горизонтальное масштабирование, но требует настройки                                  | Горизонтальное масштабирование, поддержка кластеров                     | Горизонтальное масштабирование, но может быть дорого                       | Масштабируемость ограничена по сравнению с ELK и Splunk                         |
| **Аналитические возможности** | Мощные инструменты для анализа и визуализации данных (Kibana)                         | Поддержка аналитики и визуализации, но меньше возможностей, чем в ELK   | Широкие возможности для анализа и визуализации данных                      | Хорошие возможности для анализа, но менее мощные, чем в ELK и Splunk            |
| **Интеграция**                | Легко интегрируется с различными источниками данных                                   | Хорошая интеграция с AWS и другими системами                            | Широкие возможности интеграции, но может требовать дополнительных затрат   | Легко интегрируется с различными системами, но может потребовать настройки      |
| **Стоимость**                 | Бесплатно (с открытым исходным кодом) или платные версии                              | Бесплатно (с открытым исходным кодом)                                   | Высокая стоимость лицензий и поддержки                                     | Бесплатная версия доступна, но платные функции могут быть дорогими              |

### Обоснование выбора

1. **Лицензия**:
    - **ELK Stack**: Elastic License может ограничивать использование в некоторых случаях, особенно для коммерческих
      приложений.
    - **OpenSearch**: Открытая лицензия (Apache 2.0) позволяет свободно использовать и модифицировать, что делает его
      привлекательным для компаний, стремящихся избежать лицензионных ограничений.
    - **Splunk**: Проприетарная лицензия может быть дорогой, особенно для больших объемов данных.
    - **Graylog**: Открытая лицензия (GPL) позволяет использовать и модифицировать, но может иметь ограничения на
      коммерческое использование.

2. **Производительность**:
    - **ELK Stack**: Высокая производительность, но может потребовать оптимизации для больших объемов данных.
    - **OpenSearch**: Оптимизирован для работы с большими данными, что делает его хорошим выбором для масштабируемых
      решений.
    - **Splunk**: Обеспечивает очень высокую производительность, но может требовать значительных ресурсов.
    - **Graylog**: Хорошая производительность, но может быть ограничена при больших объемах данных.

3. **Масштабируемость**:
    - **ELK Stack**: Поддерживает горизонтальное масштабирование, но требует настройки.
    - **OpenSearch**: Также поддерживает горизонтальное масштабирование и кластеризацию, что делает его подходящим для
      больших систем.
    - **Splunk**: Поддерживает масштабирование, но может быть дорогостоящим.
    - **Graylog**: Масштабируемость ограничена по сравнению с другими решениями.

4. **Аналитические возможности**:
    - **ELK Stack**: Мощные инструменты для анализа и визуализации данных через Kibana.
    - **OpenSearch**: Поддерживает аналитику и визуализацию, но с меньшими возможностями, чем ELK.
    - **Splunk**: Широкие возможности для анализа и визуализации, но может требовать дополнительных затрат.
    - **Graylog**: Хорошие возможности для анализа, но менее мощные, чем в ELK и Splunk.

5. **Стоимость**:
    - **ELK Stack**: Бесплатно (с открытым исходным кодом) или платные версии, что делает его доступным для многих
      компаний.
    - **OpenSearch**: Бесплатно (с открытым исходным кодом), что позволяет избежать лицензионных затрат.
    - **Splunk**: Высокая стоимость лицензий и поддержки может быть значительным фактором для компаний с ограниченным
      бюджетом